File: C:\Users\User\python_code\sql_conversion_test\.gitignore
================================================================================
# Ignore all SQL files by default
*.sql

# Exception: Include SQL test fixtures 
!sql-query-converter/sql_converter/tests/fixtures/**/*.sql

# Output directories
converted/
converted_sql/
output/

################################################################################

File: C:\Users\User\python_code\sql_conversion_test\basic_query.sql
================================================================================
SELECT DISTINCT 
     a.dog,
     b.cat,
     c.cow
     INTO #ANIMALS
     FROM table_a a
     INNER JOIN (
      SELECT setsk, animalsk
      FROM table_b b
      WHERE setsk = 1920
     ) b ON a.setsk = b.setsk
     LEFT JOIN table_c c ON a.setsk = c.setsk;

    SELECT * FROM #ANIMALS;

################################################################################

File: C:\Users\User\python_code\sql_conversion_test\conversions.log
================================================================================


################################################################################

File: C:\Users\User\python_code\sql_conversion_test\query_full.sql
================================================================================
SELECT DISTINCT 
    fdm.setsk, 
    fdm.dealsk, 
    buh.busunithlevel02name, 
    re.glreportingentitycode, 
    drea.glreportingentitycode AS affglreportingentitycode, 
    dmt.measuretypecode, 
    gla.glaccountcode, 
    dpt.productgroup 
INTO #distinct_deal_measure
FROM miris.dimdealset dds
INNER JOIN (
    SELECT 
        setsk, dealsk, glbusinessunitsk, measuretypesk, glaccountsk, glreportingentitysk 
    FROM miris.factdealmeasure fdm 
    WHERE setsk = 15658
) fdm 
ON dds.dealsk = fdm.dealsk AND fdm.setsk = 15658 AND dds.setsk = 15658
LEFT JOIN dbo.gldimaccount gla 
ON gla.glaccountsk = fdm.glaccountsk
LEFT JOIN dbo.dimmeasuretype dmt 
ON fdm.measuretypesk = dmt.measuretypesk
LEFT JOIN dbo.dimproducttype dpt 
ON dpt.producttypesk = dds.producttypesk
LEFT JOIN dbo.gldimbusinessunithierarchy buh 
ON fdm.glbusinessunitsk = buh.glbusinessunitsk 
AND buh.busunithtrecode = 'bunit_stat' 
AND buh.rowstatus = 'A'
LEFT JOIN dbo.gldimreportingentity re 
ON fdm.glreportingentitysk = re.glreportingentitysk
LEFT JOIN dbo.gldimreportingentity drea 
ON dds.glaffiliatereportingentitysk = drea.glreportingentitysk
INNER JOIN (
    SELECT DISTINCT 
        reg.glreportingentitysk, 
        reg.glreportingentitycode, 
        cr.reportingconsumercode 
    FROM dbo.dimglreportingentitygroupmembership reg
    INNER JOIN dbo.dimglconsumerelevance cr
    ON reg.glreportingentitygroupcode = cr.glreportingentitygroupcode 
    AND cr.rowstatus = 'A'
    WHERE cr.reportingconsumercode LIKE '%EMEA%'
    AND reg.rowstatus = 'A'
) emea 
ON emea.glreportingentitysk = dds.glreportingentitysk
WHERE fdm.setsk = 15658
AND NOT (
    (re.glreportingentitycode = drea.glreportingentitycode) 
    AND SUBSTRING(gla.glaccountcode, 5, 2) = '99'
);


################################################################################

File: C:\Users\User\python_code\sql_conversion_test\read_me.txt
================================================================================
# Basic command
python -m sql_converter.cli -i [input_file_or_dir] -o [output_file_or_dir] -c cte

# How to use it on files within a folder
python -m sql_converter.cli -i sql_files/ -o converted_files/

# How to run tests
C:\Users\User\python_code\sql_conversion_test>python -m pytest

################################################################################

File: C:\Users\User\python_code\sql_conversion_test\sql_conversion.log
================================================================================
=== Starting Conversion ===
Split into 2 statements
Reconstructed query for distinct_deal_measure:
SELECT DISTINCT 
        fdm.setsk, 
        fdm.dealsk, 
        buh.busunithlevel02name, 
        re.glreportingentitycode, 
        drea.glreportingentitycode AS affglreportingentitycode, 
        dmt.measuretypecode, 
        gla.glaccountcode, 
        dpt.productgroup
FROM miris.dimdealset dds
    INNER JOIN (
        SELECT 
            setsk, dealsk, glbusinessunitsk, measuretypesk, glaccountsk, glreportingentitysk 
        FROM miris.factdealmeasure fdm 
        WHERE setsk = 15658
    ...


################################################################################

File: C:\Users\User\python_code\sql_conversion_test\test.sql
================================================================================
WITH temp AS (
  SELECT *
  FROM users;
)


################################################################################

File: C:\Users\User\python_code\sql_conversion_test\__init__.py
================================================================================



################################################################################

File: C:\Users\User\python_code\sql_conversion_test\.pytest_cache\v\cache\nodeids
================================================================================
[
  "sql-query-converter/sql_converter/tests/integration/test_cli.py::test_cli_file_conversion",
  "sql-query-converter/sql_converter/tests/integration/test_cli.py::test_cli_help",
  "sql-query-converter/sql_converter/tests/integration/test_integration.py::test_config_loading_from_multiple_sources",
  "sql-query-converter/sql_converter/tests/integration/test_integration.py::test_directory_structure_preservation",
  "sql-query-converter/sql_converter/tests/integration/test_integration.py::test_error_handling",
  "sql-query-converter/sql_converter/tests/integration/test_integration.py::test_full_conversion",
  "sql-query-converter/sql_converter/tests/unit/converters/test_cte.py::test_basic_cte_conversion",
  "sql-query-converter/sql_converter/tests/unit/converters/test_cte.py::test_multiple_temp_tables",
  "sql-query-converter/sql_converter/tests/unit/converters/test_cte.py::test_nested_temp_tables",
  "sql-query-converter/sql_converter/tests/unit/converters/test_cte.py::test_temp_table_pattern_matching",
  "sql-query-converter/sql_converter/tests/unit/parsers/test_sql_parser.py::test_comment_handling",
  "sql-query-converter/sql_converter/tests/unit/parsers/test_sql_parser.py::test_statement_splitting",
  "sql-query-converter/sql_converter/tests/unit/parsers/test_sql_parser.py::test_tsql_bracket_handling",
  "sql-query-converter/sql_converter/tests/unit/utils/test_config.py::test_config_loading",
  "sql-query-converter/sql_converter/tests/unit/utils/test_config.py::test_config_priority"
]

################################################################################

File: C:\Users\User\python_code\sql_conversion_test\.pytest_cache\v\cache\stepwise
================================================================================
[]

################################################################################

File: C:\Users\User\python_code\sql_conversion_test\sql-query-converter\basic_query.sql
================================================================================
SELECT DISTINCT 
     a.dog,
     b.cat,
     c.cow
     INTO #ANIMALS
     FROM table_a a
     INNER JOIN (
      SELECT setsk, animalsk
      FROM table_b b
      WHERE setsk = 1920
     ) b ON a.setsk = b.setsk
     LEFT JOIN table_c c ON a.setsk = c.setsk;

    SELECT * FROM #ANIMALS;

################################################################################

File: C:\Users\User\python_code\sql_conversion_test\sql-query-converter\component_responsibilities.csv
================================================================================
﻿File/Folder,Responsibilities,Dependencies
cli.py,"Entry point, argument parsing, workflow orchestration","All converters, utils"
converters/base.py,"Define converter interface, common functionality","utils.config, utils.logging"
converters/cte.py,Temp table → CTE conversion logic,"parsers, utils"
parsers/sql_parser.py,"SQL statement splitting, tokenization, syntax analysis",(pure Python)
utils/config.py,Load/merge configurations from files/ENV/CLI,(YAML/ENV handling)
utils/logging.py,Configure logging system,Python logging
tests/,Verify component behavior,"pytest, fixtures"


################################################################################

File: C:\Users\User\python_code\sql_conversion_test\sql-query-converter\conversions.log
================================================================================
2025-02-09 19:40:50,895 - SQLConverterApp - INFO - Processing file: C:\Users\User\python_code\sql_conversion\test.sql
2025-02-09 19:40:50,899 - SQLConverterApp - INFO - Saved converted SQL to: converted
2025-02-10 06:44:35,052 - root - ERROR - Fatal error: Invalid input path: input.sql
2025-02-10 06:45:57,908 - root - ERROR - Fatal error: Invalid input path: test.sql
2025-02-10 06:46:16,291 - SQLConverterApp - INFO - Processing file: C:\Users\User\python_code\sql_conversion\sql-query-converter\sql_converter\test.sql
2025-02-10 06:46:16,291 - SQLConverterApp - INFO - Saved converted SQL to: output.sql
2025-02-10 06:48:58,965 - SQLConverterApp - INFO - Processing file: C:\Users\User\python_code\sql_conversion\sql-query-converter\sql_converter\test.sql
2025-02-10 06:48:58,965 - SQLConverterApp - INFO - Saved converted SQL to: output.sql
2025-02-10 07:01:27,981 - root - ERROR - Fatal error: Invalid input path: input.sql
2025-02-10 07:01:48,025 - SQLConverterApp - INFO - Processing file: C:\Users\User\python_code\sql_conversion\test.sql
2025-02-10 07:01:48,025 - SQLConverterApp - INFO - Saved converted SQL to: output.sql
2025-02-10 07:02:04,142 - SQLConverterApp - INFO - Processing file: C:\Users\User\python_code\sql_conversion\basic_query.sql
2025-02-10 07:02:04,142 - SQLConverterApp - INFO - Saved converted SQL to: output.sql
2025-02-10 07:02:45,659 - SQLConverterApp - INFO - Processing file: C:\Users\User\python_code\sql_conversion\basic_query.txt
2025-02-10 07:02:45,674 - SQLConverterApp - INFO - Saved converted SQL to: output.sql
2025-02-10 07:03:08,301 - SQLConverterApp - INFO - Processing file: C:\Users\User\python_code\sql_conversion\sql_query_full.txt
2025-02-10 07:03:08,316 - SQLConverterApp - INFO - Saved converted SQL to: output.sql
2025-02-25 13:42:42,064 - SQLConverterApp - INFO - Processing file: C:\Users\User\python_code\sql_conversion\test.sql
2025-02-25 13:42:42,064 - SQLConverterApp - INFO - Saved converted SQL to: C:\Users\User\python_code\sql_conversion\test.sql


################################################################################

File: C:\Users\User\python_code\sql_conversion_test\sql-query-converter\converted
================================================================================
SELECT * INTO #temp FROM users;

################################################################################

File: C:\Users\User\python_code\sql_conversion_test\sql-query-converter\execution.txt
================================================================================
User → cli.py → ConfigManager → SQLConverterApp → CTEConverter → SQLParser
            ↳ Logging          ↳ File I/O         ↳ PivotConverter

################################################################################

File: C:\Users\User\python_code\sql_conversion_test\sql-query-converter\extract_code.py
================================================================================
import os

def collect_all_files(root_dir, output_file):
    with open(output_file, 'w', encoding='utf-8') as out_f:
        for dirpath, _, filenames in os.walk(root_dir):
            if "__pycache__" in dirpath:
                continue  # Skip __pycache__ directories
            for filename in filenames:
                if filename == output_file:
                    continue
                file_path = os.path.join(dirpath, filename)
                try:
                    with open(file_path, 'r', encoding='utf-8', errors='ignore') as file:
                        content = file.read()
                        out_f.write(f"File: {file_path}\n")
                        out_f.write("=" * 80 + "\n")
                        out_f.write(content + "\n\n")
                        out_f.write("#" * 80 + "\n\n")
                except Exception as e:
                    print(f"Could not read {file_path}: {e}")

if __name__ == "__main__":
    root_directory = input("Enter the directory path to scan: ")
    output_filename = "collected_files.txt"
    collect_all_files(root_directory, output_filename)
    print(f"All files collected and saved in {output_filename}")

################################################################################

File: C:\Users\User\python_code\sql_conversion_test\sql-query-converter\file-structure.txt
================================================================================
sql-query-converter/
├── sql_converter/
│   ├── __init__.py              # Package initialization
│   │
│   ├── cli.py                   # Command-line interface (entry point)
│   │                            # Depends on: converters, utils.config, utils.logging
│   │
│   ├── converters/              # Conversion logic implementations
│   │   ├── __init__.py          # Exports converter classes
│   │   ├── base.py              # BaseConverter (abstract class)
│   │   ├── cte.py               # CTEConverter (temp table → CTE)
│   │   └── pivot.py             # PivotConverter (future implementation)
│   │
│   ├── parsers/                 # SQL parsing components
│   │   ├── __init__.py          # Exports parser classes
│   │   ├── sql_parser.py        # SQLParser (statement splitting/tokenization)
│   │   └── tokenizer.py         # Advanced tokenization (if needed)
│   │
│   ├── utils/                   # Shared utilities
│   │   ├── __init__.py          # Utility exports
│   │   ├── config.py            # ConfigManager (configuration handling)
│   │   ├── logging.py           # Logging setup
│   │   ├── formatting.py        # SQL pretty-printing
│   │   └── helpers.py           # Generic helper functions
│   │
│   └── exceptions.py            # Custom exceptions
│
├── tests/                       # Unit tests
│   ├── __init__.py              # Test package
│   ├── test_cte_converter.py    # CTE converter tests
│   ├── test_sql_parser.py       # Parser tests
│   └── fixtures/                # Test SQL files
│       ├── input/               # Sample input SQL
│       └── expected/            # Expected output SQL
│
├── docs/                        # Documentation
│   ├── usage.md                 # User guide
│   └── api.md                   # Developer documentation
│
├── examples/                    # Usage examples
│   ├── basic_usage.py           # Simple API example
│   └── sample_queries/          # Example SQL files
│
├── scripts/                     # Maintenance scripts
│   ├── benchmark.py             # Performance testing
│   └── validate_config.py       # Config validation
│
├── config/                      # Default configurations
│   └── default.yml              # Base configuration
│
├── .gitignore                   # Version control ignore
├── pyproject.toml               # Build configuration
├── README.md                    # Project overview
└── requirements.txt             # Dependencies

################################################################################

File: C:\Users\User\python_code\sql_conversion_test\sql-query-converter\output.sql
================================================================================
WITH distinct_deal_measure AS (
  SELECT DISTINCT 
      fdm.setsk, 
      fdm.dealsk, 
      buh.busunithlevel02name, 
      re.glreportingentitycode, 
      drea.glreportingentitycode AS affglreportingentitycode, 
      dmt.measuretypecode, 
      gla.glaccountcode, 
      dpt.productgroup
  FROM miris.dimdealset dds
  INNER JOIN (
      SELECT 
          setsk, dealsk, glbusinessunitsk, measuretypesk, glaccountsk, glreportingentitysk 
      FROM miris.factdealmeasure fdm 
      WHERE setsk = 15658
  ) fdm 
  ON dds.dealsk = fdm.dealsk AND fdm.setsk = 15658 AND dds.setsk = 15658
  LEFT JOIN dbo.gldimaccount gla 
  ON gla.glaccountsk = fdm.glaccountsk
  LEFT JOIN dbo.dimmeasuretype dmt 
  ON fdm.measuretypesk = dmt.measuretypesk
  LEFT JOIN dbo.dimproducttype dpt 
  ON dpt.producttypesk = dds.producttypesk
  LEFT JOIN dbo.gldimbusinessunithierarchy buh 
  ON fdm.glbusinessunitsk = buh.glbusinessunitsk 
  AND buh.busunithtrecode = 'bunit_stat' 
  AND buh.rowstatus = 'A'
  LEFT JOIN dbo.gldimreportingentity re 
  ON fdm.glreportingentitysk = re.glreportingentitysk
  LEFT JOIN dbo.gldimreportingentity drea 
  ON dds.glaffiliatereportingentitysk = drea.glreportingentitysk
  INNER JOIN (
      SELECT DISTINCT 
          reg.glreportingentitysk, 
          reg.glreportingentitycode, 
          cr.reportingconsumercode 
      FROM dbo.dimglreportingentitygroupmembership reg
      INNER JOIN dbo.dimglconsumerelevance cr
      ON reg.glreportingentitygroupcode = cr.glreportingentitygroupcode 
      AND cr.rowstatus = 'A'
      WHERE cr.reportingconsumercode LIKE '%EMEA%'
      AND reg.rowstatus = 'A'
  ) emea 
  ON emea.glreportingentitysk = dds.glreportingentitysk
  WHERE fdm.setsk = 15658
  AND NOT (
      (re.glreportingentitycode = drea.glreportingentitycode) 
      AND SUBSTRING(gla.glaccountcode, 5, 2) = '99'
  );
)


################################################################################

File: C:\Users\User\python_code\sql_conversion_test\sql-query-converter\requirements-test.txt
================================================================================
pytest>=7.0
pytest-mock>=3.0
freezegun>=1.0

################################################################################

File: C:\Users\User\python_code\sql_conversion_test\sql-query-converter\sql_converter.yml
================================================================================
converters:
  - cte

logging:
  level: DEBUG
  file: conversions.log

cte_converter:
  indent_spaces: 2
  temp_table_patterns:
    - "#?temp_*"
    - "#?tmp_*"
    - "#.*"

output:
  default_output_dir: ./converted_sql
  overwrite: true

################################################################################

File: C:\Users\User\python_code\sql_conversion_test\sql-query-converter\test.sql
================================================================================
WITH temp AS (
  SELECT *
  FROM users;
)


################################################################################

File: C:\Users\User\python_code\sql_conversion_test\sql-query-converter\.pytest_cache\.gitignore
================================================================================
# Created by pytest automatically.
*


################################################################################

File: C:\Users\User\python_code\sql_conversion_test\sql-query-converter\.pytest_cache\CACHEDIR.TAG
================================================================================
Signature: 8a477f597d28d172789f06886806bc55
# This file is a cache directory tag created by pytest.
# For information about cache directory tags, see:
#	https://bford.info/cachedir/spec.html


################################################################################

File: C:\Users\User\python_code\sql_conversion_test\sql-query-converter\.pytest_cache\README.md
================================================================================
# pytest cache directory #

This directory contains data from the pytest's cache plugin,
which provides the `--lf` and `--ff` options, as well as the `cache` fixture.

**Do not** commit this to version control.

See [the docs](https://docs.pytest.org/en/stable/how-to/cache.html) for more information.


################################################################################

File: C:\Users\User\python_code\sql_conversion_test\sql-query-converter\.pytest_cache\v\cache\lastfailed
================================================================================
{
  "sql_converter/tests/integration/test_integration.py::test_full_conversion": true,
  "sql_converter/tests/integration/test_integration.py::test_error_handling": true,
  "sql_converter/tests/unit/converters/test_cte.py::test_nested_temp_tables": true
}

################################################################################

File: C:\Users\User\python_code\sql_conversion_test\sql-query-converter\.pytest_cache\v\cache\nodeids
================================================================================
[
  "sql_converter/tests/integration/test_cli.py::test_cli_file_conversion",
  "sql_converter/tests/integration/test_cli.py::test_cli_help",
  "sql_converter/tests/integration/test_integration.py::test_config_loading_from_multiple_sources",
  "sql_converter/tests/integration/test_integration.py::test_directory_structure_preservation",
  "sql_converter/tests/integration/test_integration.py::test_error_handling",
  "sql_converter/tests/integration/test_integration.py::test_full_conversion",
  "sql_converter/tests/unit/converters/test_cte.py::test_basic_cte_conversion",
  "sql_converter/tests/unit/converters/test_cte.py::test_multiple_temp_tables",
  "sql_converter/tests/unit/converters/test_cte.py::test_nested_temp_tables",
  "sql_converter/tests/unit/converters/test_cte.py::test_temp_table_pattern_matching",
  "sql_converter/tests/unit/parsers/test_sql_parser.py::test_comment_handling",
  "sql_converter/tests/unit/parsers/test_sql_parser.py::test_statement_splitting",
  "sql_converter/tests/unit/parsers/test_sql_parser.py::test_tsql_bracket_handling",
  "sql_converter/tests/unit/utils/test_config.py::test_config_loading",
  "sql_converter/tests/unit/utils/test_config.py::test_config_priority"
]

################################################################################

File: C:\Users\User\python_code\sql_conversion_test\sql-query-converter\.pytest_cache\v\cache\stepwise
================================================================================
[]

################################################################################

File: C:\Users\User\python_code\sql_conversion_test\sql-query-converter\sql_converter\cli.py
================================================================================
import os
import argparse
import logging
import sys
from pathlib import Path
from typing import Dict, List, Any, Optional, Set, Tuple
import traceback

from sql_converter.converters import get_converter
from sql_converter.utils.config import ConfigManager
from sql_converter.utils.logging import setup_logging
from sql_converter.converters.base import BaseConverter
from sql_converter.exceptions import (
    SQLConverterError, ConfigError, ValidationError, 
    SQLSyntaxError, FileError, ConverterError
)


class SQLConverterApp:
    """
    Main application for SQL conversion, handling workflow orchestration.
    """
    
    def __init__(self, converters: Dict[str, BaseConverter], config: Dict[str, Any]):
        """
        Initialize the SQL Converter Application.
        
        Args:
            converters: Dictionary of converter name to converter instance
            config: Configuration dictionary
            
        Raises:
            ConfigError: When initialization fails due to config issues
        """
        if not converters:
            raise ConfigError("No converters provided")
            
        self.converters = converters
        self.config = config
        self.logger = logging.getLogger(self.__class__.__name__)
        
        # Track processed files for reporting
        self.processed_files: Set[Path] = set()
        self.failed_files: Set[Tuple[Path, str]] = set()  # (path, error_message)

    def process_file(self, input_path: Path, output_path: Path, conversions: List[str]) -> None:
        """
        Process a single SQL file.
        
        Args:
            input_path: Path to input SQL file
            output_path: Path to output SQL file
            conversions: List of converter names to apply
            
        Raises:
            FileError: When file operations fail
            ConverterError: When conversion fails
            ValidationError: When SQL validation fails
        """
        if not input_path.exists():
            raise FileError(f"Input file does not exist", filepath=str(input_path))
            
        if not input_path.is_file():
            raise FileError(f"Input path is not a file", filepath=str(input_path))
            
        # Check file access
        if not os.access(input_path, os.R_OK):
            raise FileError(f"No read permission for input file", filepath=str(input_path))
            
        # Ensure output directory exists and is writable
        output_dir = output_path.parent
        output_dir.mkdir(parents=True, exist_ok=True)
        
        if output_dir.exists() and not os.access(output_dir, os.W_OK):
            raise FileError(f"No write permission for output directory", 
                           filepath=str(output_dir))
            
        try:
            self.logger.info(f"Processing file: {input_path}")
            
            # Read input file with proper error handling
            try:
                sql = input_path.read_text(encoding='utf-8')
            except UnicodeDecodeError:
                # Try with a different encoding
                try:
                    sql = input_path.read_text(encoding='latin-1')
                    self.logger.warning(f"File {input_path} was not UTF-8, read as Latin-1")
                except Exception as e:
                    raise FileError(f"Failed to read file: {str(e)}", 
                                   filepath=str(input_path)) from e
            except Exception as e:
                raise FileError(f"Failed to read file: {str(e)}", 
                               filepath=str(input_path)) from e

            # Apply conversions
            converted_sql = sql
            for conversion in conversions:
                if conversion not in self.converters:
                    raise ConverterError(f"Unknown converter: {conversion}")
                
                converter = self.converters[conversion]
                self.logger.debug(f"Applying converter '{conversion}' to {input_path}")
                
                # Apply the conversion with proper error handling
                try:
                    converted_sql = converter.convert(converted_sql)
                except Exception as e:
                    # Preserve error type if it's a known one, otherwise wrap
                    if isinstance(e, (SQLSyntaxError, ValidationError, ConverterError)):
                        raise
                    raise ConverterError(
                        f"Error in {conversion} converter: {str(e)}",
                        source=input_path.name
                    ) from e

            # Write output file with proper error handling
            try:
                output_path.write_text(converted_sql, encoding='utf-8')
                self.logger.info(f"Saved converted SQL to: {output_path}")
                self.processed_files.add(input_path)
            except Exception as e:
                raise FileError(f"Failed to write output file: {str(e)}", 
                               filepath=str(output_path)) from e

        except Exception as e:
            self.logger.error(f"Failed to process {input_path}: {str(e)}")
            self.failed_files.add((input_path, str(e)))
            raise

    def process_directory(self, input_dir: Path, output_dir: Path, conversions: List[str]) -> None:
        """
        Process all SQL files in a directory, preserving the directory structure.
        
        Args:
            input_dir: Directory containing SQL files to process
            output_dir: Directory to write converted SQL files to
            conversions: List of converter names to apply
            
        Raises:
            FileError: When directory operations fail
        """
        if not input_dir.exists():
            raise FileError(f"Input directory does not exist", filepath=str(input_dir))
            
        if not input_dir.is_dir():
            raise FileError(f"Input path is not a directory", filepath=str(input_dir))
            
        # Process sql files while preserving directory structure
        try:
            for input_path in input_dir.glob("**/*.sql"):
                if input_path.is_file():
                    # Calculate relative path to preserve directory structure
                    relative_path = input_path.relative_to(input_dir)
                    output_path = output_dir / relative_path
                    
                    try:
                        self.process_file(input_path, output_path, conversions)
                    except Exception as e:
                        self.logger.error(f"Error processing {input_path}: {e}")
                        # Continue processing other files
                        continue
                        
            # Check if we processed any files
            if not self.processed_files and not self.failed_files:
                self.logger.warning(f"No SQL files found in {input_dir}")
                
        except Exception as e:
            if isinstance(e, FileError):
                raise
            raise FileError(f"Error processing directory: {str(e)}", 
                           filepath=str(input_dir)) from e

    def get_summary(self) -> Dict[str, Any]:
        """
        Generate a summary of processing results.
        
        Returns:
            Dictionary with processing statistics
        """
        return {
            'processed_files': len(self.processed_files),
            'failed_files': len(self.failed_files),
            'success_rate': (
                len(self.processed_files) / 
                (len(self.processed_files) + len(self.failed_files))
                if (len(self.processed_files) + len(self.failed_files)) > 0 
                else 0
            ) * 100,
            'failures': [
                {'file': str(path), 'error': error} 
                for path, error in self.failed_files
            ]
        }


def main():
    """
    Main entry point for SQL converter CLI application.
    
    This function parses command-line arguments, initializes the application,
    and orchestrates the conversion process with comprehensive error handling.
    """
    # Initialize base logging before config
    logging.basicConfig(level=logging.WARNING)
    logger = logging.getLogger()
    
    try:
        # Initialize configuration
        config_manager = ConfigManager()
        
        try:
            config_manager.load_config()
        except ConfigError as e:
            logger.error(f"Configuration error: {e}")
            sys.exit(1)
            
        # Validate configuration
        validation_errors = config_manager.validate_config()
        if validation_errors:
            logger.warning("Configuration validation issues:")
            for error in validation_errors:
                logger.warning(f"  - {error}")

        # Setup logging with config
        try:
            setup_logging(
                level=config_manager.get('logging.level', 'INFO'),
                log_file=config_manager.get('logging.file')
            )
        except Exception as e:
            logger.error(f"Failed to configure logging: {e}")
            # Continue with basic logging

        # Parse command line arguments with better error handling
        parser = argparse.ArgumentParser(
            description='SQL Query Conversion Tool',
            formatter_class=argparse.ArgumentDefaultsHelpFormatter
        )
        
        parser.add_argument(
            '-i', '--input',
            type=Path,
            required=True,
            help='Input file or directory'
        )
        parser.add_argument(
            '-o', '--output',
            type=Path,
            required=True,
            help='Output file or directory'
        )
        
        # Get available converters before adding CLI arguments
        try:
            available_converters = [name for name in config_manager.get('converters', ['cte'])]
            
            parser.add_argument(
                '-c', '--convert',
                nargs='+',
                choices=available_converters,
                default=available_converters,
                help='Conversion operations to apply'
            )
        except Exception as e:
            logger.error(f"Failed to initialize converters list: {e}")
            available_converters = ['cte']  # Fallback
            
            parser.add_argument(
                '-c', '--convert',
                nargs='+',
                default=['cte'],
                help='Conversion operations to apply (failed to load converter list)'
            )

        # Add verbosity control
        parser.add_argument(
            '-v', '--verbose',
            action='store_true',
            help='Enable verbose output'
        )
        
        # Parse arguments
        try:
            args = parser.parse_args()
        except Exception as e:
            logger.error(f"Argument parsing error: {e}")
            parser.print_help()
            sys.exit(1)

        # Update verbosity
        if args.verbose:
            logger.setLevel(logging.DEBUG)
            for handler in logger.handlers:
                handler.setLevel(logging.DEBUG)

        # Update config with CLI arguments
        config_manager.update_from_cli(vars(args))

        # Initialize converters with config
        try:
            converters = {
                name: get_converter(name, config_manager.get(f"{name}_converter", {}))
                for name in config_manager.get('converters', ['cte'])
            }
        except Exception as e:
            logger.error(f"Failed to initialize converters: {e}")
            sys.exit(1)

        # Initialize application
        try:
            app = SQLConverterApp(converters, config_manager.config)
        except ConfigError as e:
            logger.error(f"Application initialization error: {e}")
            sys.exit(1)

        # Process input
        try:
            input_path = config_manager.get('input_path', args.input)
            output_path = config_manager.get('output_path', args.output)

            if input_path.is_file():
                if output_path.exists() and output_path.is_dir():
                    output_path = output_path / input_path.name
                app.process_file(input_path, output_path, args.convert)
                
            elif input_path.is_dir():
                app.process_directory(input_path, output_path, args.convert)
                
            else:
                raise FileError(f"Invalid input path: {input_path}")
                
            # Print summary
            summary = app.get_summary()
            logger.info(f"Processing complete: {summary['processed_files']} files processed, "
                      f"{summary['failed_files']} files failed "
                      f"({summary['success_rate']:.1f}% success rate)")
                      
            if summary['failed_files'] > 0:
                logger.warning("Failed files:")
                for failure in summary['failures'][:5]:  # Show the first 5 failures
                    logger.warning(f"  {failure['file']}: {failure['error']}")
                    
                if len(summary['failures']) > 5:
                    logger.warning(f"  ... and {len(summary['failures']) - 5} more failures")
                    
                # Exit with error code if there were failures
                sys.exit(1)

        except FileError as e:
            logger.error(f"File error: {e}")
            sys.exit(1)
        except ConverterError as e:
            logger.error(f"Converter error: {e}")
            sys.exit(1)
        except SQLSyntaxError as e:
            logger.error(f"SQL syntax error: {e}")
            sys.exit(1)
        except Exception as e:
            logger.error(f"Unexpected error: {e}")
            if args.verbose:
                logger.error(traceback.format_exc())
            sys.exit(1)

    except Exception as e:
        # Last resort error handling
        logger.error(f"Critical error: {e}")
        sys.exit(1)


if __name__ == '__main__':
    main()

################################################################################

File: C:\Users\User\python_code\sql_conversion_test\sql-query-converter\sql_converter\exceptions.py
================================================================================
"""
Custom exception classes for SQL Converter.

This module contains all exception types used throughout the SQL Converter application,
providing a consistent error handling approach and meaningful error messages.
"""
from typing import Optional


class SQLConverterError(Exception):
    """Base exception for all SQL Converter errors."""
    
    def __init__(self, message: str, source: Optional[str] = None):
        self.source = source
        self.message = message
        super().__init__(f"{message} {f'[Source: {source}]' if source else ''}")


class ConfigError(SQLConverterError):
    """Raised when there's an issue with configuration."""
    pass


class ValidationError(SQLConverterError):
    """Raised when validation of inputs fails."""
    pass


class SQLSyntaxError(ValidationError):
    """Raised when SQL syntax is invalid."""
    
    def __init__(self, message: str, source: Optional[str] = None, 
                 position: Optional[int] = None, line: Optional[int] = None):
        self.position = position
        self.line = line
        location_info = ""
        if line is not None:
            location_info += f" at line {line}"
        if position is not None:
            location_info += f" at position {position}"
        
        super().__init__(f"SQL syntax error{location_info}: {message}", source)


class ParserError(SQLConverterError):
    """Raised when there's an error during SQL parsing."""
    pass


class ConverterError(SQLConverterError):
    """Raised when there's an error during SQL conversion."""
    pass


class FileError(SQLConverterError):
    """Raised when there's an issue with file operations."""
    
    def __init__(self, message: str, filepath: Optional[str] = None):
        self.filepath = filepath
        super().__init__(f"{message} {f'[File: {filepath}]' if filepath else ''}")


class PluginError(SQLConverterError):
    """Raised when there's an issue with a plugin or extension."""
    pass

################################################################################

File: C:\Users\User\python_code\sql_conversion_test\sql-query-converter\sql_converter\__init__.py
================================================================================
__all__ = ['main']

################################################################################

File: C:\Users\User\python_code\sql_conversion_test\sql-query-converter\sql_converter\converters\base.py
================================================================================
# File: sql-query-converter/sql_converter/converters/base.py
from abc import ABC, abstractmethod
from typing import Dict, Any
import logging

class BaseConverter(ABC):

    def __init__(self, config: Dict[str, Any] = None):
        self.config = config or {}
        self.logger = logging.getLogger(self.__class__.__name__)

    @abstractmethod
    def convert(self, sql: str) -> str:
        """Convert SQL using this converter's logic"""
        pass

__all__ = ['BaseConverter']  # Add this at the bottom

################################################################################

File: C:\Users\User\python_code\sql_conversion_test\sql-query-converter\sql_converter\converters\cte.py
================================================================================
import re
import logging
from typing import List, Tuple, Dict, Optional, Any, Match, Pattern, Set

from sql_converter.converters.base import BaseConverter
from sql_converter.parsers.sql_parser import SQLParser
from sql_converter.exceptions import ConverterError, ValidationError, SQLSyntaxError, ConfigError


class CTEConverter(BaseConverter):
    """Converts SQL queries with temporary tables to Common Table Expressions (CTEs)."""
    
    # Precompile regex patterns for performance
    _SELECT_INTO_PATTERN = re.compile(
        r'^\s*SELECT\s+(?P<select_clause>.+?)\s+INTO\s+(?P<table>\S+)\s+(?P<remainder>FROM.*)',
        re.IGNORECASE | re.DOTALL
    )
    
    _CREATE_TEMP_AS_PATTERN1 = re.compile(
        r'^\s*CREATE\s+TEMP\s+TABLE\s+(?P<table>\S+)\s+AS\s*(?P<query>SELECT.*)',
        re.IGNORECASE | re.DOTALL
    )
    
    _CREATE_TEMP_AS_PATTERN2 = re.compile(
        r'^\s*CREATE\s+TEMP\s+TABLE\s+(?P<table>\S+)\s+AS\s*\((?P<query>SELECT.*?)(?:\)|;|\s*$)',
        re.IGNORECASE | re.DOTALL
    )
    
    _CREATE_TEMP_PATTERN = re.compile(
        r'^\s*CREATE\s+TEMP\s+TABLE\s+(?P<table>\S+)',
        re.IGNORECASE
    )
    
    _INSERT_INTO_PATTERN = re.compile(
        r'^\s*INSERT\s+INTO\s+(?P<table>\S+)\s+(?P<query>SELECT.*)',
        re.IGNORECASE | re.DOTALL
    )
    
    def __init__(self, config: Dict[str, Any] = None):
        """
        Initialize CTEConverter with configuration.
        
        Args:
            config: Configuration dictionary for converter settings
        """
        super().__init__(config)
        self.logger = logging.getLogger(self.__class__.__name__)
        
        # Configuration with defaults
        self.indent_spaces = self.config.get('indent_spaces', 4)
        temp_table_patterns = self.config.get('temp_table_patterns', ['#.*'])
        
        # Initialize components
        self.parser = SQLParser()
        
        # Compile temp table regex from patterns
        try:
            self.temp_table_regex = self._process_patterns(temp_table_patterns)
        except Exception as e:
            raise ConfigError(f"Failed to process temp table patterns: {str(e)}")
        
        # Conversion state - will be reset for each conversion
        self.temp_tables = {}
        self.temp_table_order = []  # Track order of appearance
        self.current_temp_table = None

    def _process_patterns(self, patterns: List[str]) -> str:
        """
        Convert configuration patterns to regex pattern.
        
        Args:
            patterns: List of pattern strings
            
        Returns:
            Compiled regex pattern string
            
        Raises:
            ConfigError: When pattern processing fails
        """
        if not patterns:
            raise ConfigError("No temp table patterns provided")
            
        regex_fragments = []
        for i, pattern in enumerate(patterns):
            try:
                # Convert simplified pattern to regex
                processed = (
                    pattern.replace('?', '.?')
                           .replace('*', '.*')
                           .replace('#', r'\#')
                )
                regex_fragments.append(processed)
            except Exception as e:
                self.logger.warning(f"Invalid pattern '{pattern}' at index {i}: {str(e)}")
        
        if not regex_fragments:
            self.logger.warning("No valid patterns found, using default pattern '#.*'")
            return r'\#.*'
            
        return '|'.join(regex_fragments)

    def convert(self, sql: str) -> str:
        """
        Convert SQL with temp tables to use CTEs.
        
        Args:
            sql: SQL query text to convert
            
        Returns:
            Converted SQL using CTEs
            
        Raises:
            ConverterError: For general conversion errors
            ValidationError: For validation errors
            SQLSyntaxError: For SQL syntax errors
        """
        try:
            # Reset state for this conversion
            self.temp_tables = {}
            self.temp_table_order = []  # Reset temp table order
            self.current_temp_table = None
            
            # Phase 1: Split the SQL into statements
            statements = self.parser.split_statements(sql)
            
            # Phase 2: Analyze SQL and identify temp tables
            self._identify_temp_tables(statements)
            
            # Phase 3: Build dependency graph
            dependency_graph = self._build_dependency_graph(statements)
            
            # Phase 4: Generate CTEs in topological order
            ctes = self._generate_ctes(dependency_graph)
            
            # Phase 5: Transform remaining statements
            main_query = self._transform_main_query(statements)
            
            # Phase 6: Assemble the final query
            return self._assemble_final_query(ctes, main_query)
            
        except SQLSyntaxError as e:
            self.logger.error(f"SQL syntax error during conversion: {e}")
            raise
        except ValidationError as e:
            self.logger.error(f"Validation error during conversion: {e}")
            raise
        except Exception as e:
            error_msg = f"Failed to convert SQL: {str(e)}"
            self.logger.error(error_msg)
            snippet = sql[:100] + "..." if len(sql) > 100 else sql
            raise ConverterError(error_msg, source=snippet) from e

    def _identify_temp_tables(self, statements: List[str]) -> None:
        """
        Identify temporary tables and their definitions in SQL statements.
        
        Args:
            statements: List of SQL statements
        """
        # Initialize/reset the temp table order tracking
        self.temp_table_order = []
        
        for stmt in statements:
            # Check for "SELECT ... INTO #temp"
            select_into_match = self._SELECT_INTO_PATTERN.match(stmt)
            if select_into_match:
                table_name = select_into_match.group('table')
                if self._is_temp_table(table_name):
                    # Only add to order list the first time we see it
                    if table_name not in self.temp_tables:
                        self.temp_table_order.append(table_name)
                        
                    select_clause = select_into_match.group('select_clause')
                    from_clause = select_into_match.group('remainder')
                    definition = f"SELECT {select_clause}\n{from_clause}"
                    
                    self.temp_tables[table_name] = {
                        'definition': definition,
                        'cte_name': self._get_cte_name(table_name),
                        'type': 'SELECT_INTO',
                        'statement': stmt
                    }
                    continue
                    
            # Check for "CREATE TEMP TABLE #temp AS SELECT ..."
            create_temp_match = (self._CREATE_TEMP_AS_PATTERN1.match(stmt) or 
                                self._CREATE_TEMP_AS_PATTERN2.match(stmt))
            if create_temp_match:
                table_name = create_temp_match.group('table')
                if self._is_temp_table(table_name):
                    # Only add to order list the first time we see it
                    if table_name not in self.temp_tables:
                        self.temp_table_order.append(table_name)
                        
                    definition = create_temp_match.group('query').strip()
                    if definition.endswith(';'):
                        definition = definition[:-1]
                    
                    self.temp_tables[table_name] = {
                        'definition': definition,
                        'cte_name': self._get_cte_name(table_name),
                        'type': 'CREATE_TEMP_AS',
                        'statement': stmt
                    }
                    continue
            
            # Check for "CREATE TEMP TABLE" followed by "INSERT INTO"
            create_temp_match = self._CREATE_TEMP_PATTERN.match(stmt)
            if create_temp_match:
                table_name = create_temp_match.group('table')
                if self._is_temp_table(table_name):
                    # Only add to order list the first time we see it
                    if table_name not in self.temp_tables:
                        self.temp_table_order.append(table_name)
                        
                    self.current_temp_table = table_name
                    continue
            
            # Check for "INSERT INTO #temp"
            if self.current_temp_table:
                insert_pattern = re.compile(
                    rf'^\s*INSERT\s+INTO\s+{re.escape(self.current_temp_table)}\s+(?P<query>SELECT.*)',
                    re.IGNORECASE | re.DOTALL
                )
                insert_match = insert_pattern.match(stmt)
                if insert_match:
                    definition = insert_match.group('query').strip()
                    if definition.endswith(';'):
                        definition = definition[:-1]
                    
                    self.temp_tables[self.current_temp_table] = {
                        'definition': definition,
                        'cte_name': self._get_cte_name(self.current_temp_table),
                        'type': 'INSERT_INTO',
                        'statement': stmt
                    }
                    self.current_temp_table = None
                    continue

    def _is_temp_table(self, table_name: str) -> bool:
        """
        Check if a table name matches temp table patterns.
        
        Args:
            table_name: Table name to check
            
        Returns:
            True if it's a temp table, False otherwise
        """
        return bool(re.search(self.temp_table_regex, table_name))

    def _get_cte_name(self, temp_name: str) -> str:
        """
        Generate a CTE name from a temp table name.
        
        Args:
            temp_name: Original temp table name
            
        Returns:
            Cleaned name suitable for a CTE
        """
        return temp_name.lstrip('#').replace('.', '_')

    def _extract_table_references(self, sql: str) -> Set[str]:
        """
        Extract all table references from SQL that match temp table patterns.
        
        Args:
            sql: SQL statement to analyze
            
        Returns:
            Set of referenced temp table names
        """
        references = set()
    
        # FIXED: Improved regex to better catch table references
        # Look for FROM/JOIN followed by anything that's not a space, comma, semicolon, or parenthesis
        pattern = re.compile(
            r'(?:FROM|JOIN)\s+(?:\w+\.)?([^\s,;()]+)',
            re.IGNORECASE
        )
        
        # Also specifically look for temp tables with # prefix
        temp_pattern = re.compile(r'#\w+', re.IGNORECASE)
        
        # Check regular FROM/JOIN references
        for match in pattern.finditer(sql):
            table_ref = match.group(1)
            if self._is_temp_table(table_ref) and table_ref in self.temp_tables:
                references.add(table_ref)
        
        # ADDED: Also look for direct # references anywhere
        for match in temp_pattern.finditer(sql):
            table_ref = match.group(0)
            if table_ref in self.temp_tables:
                references.add(table_ref)
        
        return references

    def _build_dependency_graph(self, statements: List[str]) -> Dict[str, List[str]]:
        """
        Build a dependency graph between temp tables.
        
        Args:
            statements: List of SQL statements
            
        Returns:
            Dictionary mapping temp tables to their dependencies
        """
        dependency_graph = {name: [] for name in self.temp_tables}
        
        # Process defined temp tables first
        for temp_name, temp_info in self.temp_tables.items():
            # Extract table references from the definition
            definition = temp_info['definition']
            references = self._extract_table_references(definition)
            
            for ref in references:
                if ref in self.temp_tables and ref != temp_name:  # Avoid self-references
                    dependency_graph[temp_name].append(ref)
        
        # Find any references in the main query
        for stmt in statements:
            # Skip statements that define temp tables
            if any(info['statement'] == stmt for info in self.temp_tables.values()):
                continue
                
            # Check for implicit dependencies between temp tables
            # that are referenced in the same statement
            references = self._extract_table_references(stmt)
            if len(references) > 1:
                # Multiple temp tables are referenced in this statement
                # Create implicit dependencies based on order of reference
                references_list = list(references)
                for i in range(len(references_list) - 1):
                    for j in range(i + 1, len(references_list)):
                        ref1 = references_list[i]
                        ref2 = references_list[j]
                        if ref2 not in dependency_graph[ref1]:
                            dependency_graph[ref1].append(ref2)
        
        return dependency_graph

    def _generate_ctes(self, dependency_graph: Dict[str, List[str]]) -> List[Tuple[str, str]]:
        """
        Generate CTEs in proper dependency order using topological sort while 
        preserving original order within same dependency level.
        
        Args:
            dependency_graph: Dependency graph of temp tables
            
        Returns:
            List of (cte_name, definition) tuples in proper order
        """
        # Track original order of appearance using our explicit tracking list
        original_order = {name: idx for idx, name in enumerate(self.temp_table_order)}
        
        # Helper function for topological sort
        def topological_sort():
            # Track permanent and temporary marks for cycle detection
            permanent_mark = set()
            temporary_mark = set()
            result = []
            
            def visit(node):
                if node in permanent_mark:
                    return
                if node in temporary_mark:
                    raise ValidationError(f"Circular dependency detected involving {node}")
                    
                temporary_mark.add(node)
                
                # Visit dependencies first
                for dependency in dependency_graph.get(node, []):
                    visit(dependency)
                    
                temporary_mark.remove(node)
                permanent_mark.add(node)
                result.append(node)
                
            # Visit all nodes
            for node in dependency_graph:
                if node not in permanent_mark:
                    visit(node)
                    
            return result
        
        # Get the ordered list of temp table names
        ordered_temp_tables = topological_sort()
        
        # Calculate dependency level for each table
        levels = {}
        for node in ordered_temp_tables:
            # Calculate level (max level of dependencies + 1)
            max_dep_level = 0
            for dep in dependency_graph.get(node, []):
                if dep in levels:
                    max_dep_level = max(max_dep_level, levels[dep] + 1)
            levels[node] = max_dep_level
        
        # Group nodes by level
        level_groups = {}
        for node, level in levels.items():
            if level not in level_groups:
                level_groups[level] = []
            level_groups[level].append(node)
        
        # Sort each level by original order
        for level in level_groups:
            # Use get() with a default to handle any tables not in our order list
            level_groups[level].sort(key=lambda x: original_order.get(x, float('inf')))
        
        # Build final ordered list respecting both dependencies and original order
        final_ordered_tables = []
        for level in sorted(level_groups.keys()):
            final_ordered_tables.extend(level_groups[level])
        
        # Generate CTE definitions
        ctes = []
        for temp_name in final_ordered_tables:
            # Get the cleaned name and definition
            cte_name = self.temp_tables[temp_name]['cte_name']
            definition = self.temp_tables[temp_name]['definition']
            
            # FIXED: Use the same improved pattern for replacing references
            for ref_temp_name in self.temp_tables:
                if ref_temp_name != temp_name:  # Avoid self-references
                    ref_cte_name = self.temp_tables[ref_temp_name]['cte_name']
                    # Use the same improved pattern we used in _transform_main_query
                    pattern = r'(?<![a-zA-Z0-9_])' + re.escape(ref_temp_name) + r'(?![a-zA-Z0-9_])'
                    definition = re.sub(pattern, ref_cte_name, definition, flags=re.IGNORECASE)
            
            ctes.append((cte_name, definition))
        
        return ctes

    def _is_temp_definition(self, stmt: str) -> bool:
        """
        Check if a statement defines a temp table.
        
        Args:
            stmt: SQL statement to check
            
        Returns:
            True if it defines a temp table, False otherwise
        """
        # Check if this statement matches any of the temp table definition patterns
        for temp_info in self.temp_tables.values():
            if temp_info['statement'] == stmt:
                return True
        return False

    def _transform_main_query(self, statements: List[str]) -> str:
        """
        Transform the main query by replacing temp table references with CTE names.
        
        Args:
            statements: List of SQL statements
            
        Returns:
            Transformed main query
        """
        # Filter out statements that define temp tables
        main_statements = []
        for stmt in statements:
            if not self._is_temp_definition(stmt):
                main_statements.append(stmt)
        
        # Replace temp table references in remaining statements
        transformed_statements = []
        for stmt in main_statements:
            transformed = stmt
            for temp_name, info in self.temp_tables.items():
                cte_name = info['cte_name']
                pattern = r'(?<![a-zA-Z0-9_])' + re.escape(temp_name) + r'(?![a-zA-Z0-9_])'
                transformed = re.sub(pattern, cte_name, transformed, flags=re.IGNORECASE)
            transformed_statements.append(transformed)
        
        # Join statements WITHOUT stripping semicolons
        return "\n".join(transformed_statements)  # Removed the rstrip(';

    def _assemble_final_query(self, ctes: List[Tuple[str, str]], main_query: str) -> str:
        if not ctes:
            return main_query
        
        # Sort CTEs by original appearance order
        original_order = {name: idx for idx, name in enumerate(self.temp_table_order)}
        
        # Create a mapping from CTE name to original temp table name
        cte_to_temp = {}
        for temp_name, info in self.temp_tables.items():
            cte_to_temp[info['cte_name']] = temp_name
        
        # Sort the CTEs by the original order of their corresponding temp tables
        sorted_ctes = sorted(ctes, key=lambda x: original_order.get(cte_to_temp.get(x[0], ''), float('inf')))
        
        # Format each CTE with proper indentation
        cte_clauses = []
        for name, definition in sorted_ctes:
            # Clean and indent the definition
            clean_def = definition.rstrip(';')
            indented_def = self._indent(clean_def)
            cte_clauses.append(f"{name} AS (\n{indented_def}\n)")
        
        # Check if the original query had semicolons BEFORE stripping them
        had_semicolon = main_query.rstrip().endswith(';')
        
        # Now strip the semicolon for formatting
        main_query = main_query.rstrip(';')
        
        # Use the saved flag to determine whether to add a semicolon
        if had_semicolon:
            return f"WITH {',\n'.join(cte_clauses)}\n{main_query};"
        else:
            return f"WITH {',\n'.join(cte_clauses)}\n{main_query}"

    def _indent(self, sql: str) -> str:
        """
        Apply configured indentation to SQL.
        
        Args:
            sql: SQL string to indent
            
        Returns:
            Indented SQL
        """
        indent = ' ' * self.indent_spaces
        return '\n'.join(f"{indent}{line}" for line in sql.split('\n'))

################################################################################

File: C:\Users\User\python_code\sql_conversion_test\sql-query-converter\sql_converter\converters\__init__.py
================================================================================
# sql_converter/converters/__init__.py
from .base import BaseConverter
# Register default converters
from .cte import CTEConverter
__all__ = ['CTEConverter']
_converters = {}

def register_converter(name: str, converter_class: type):
    if not issubclass(converter_class, BaseConverter):
        raise TypeError("Converters must inherit from BaseConverter")
    _converters[name] = converter_class

def get_converter(name: str, config: dict = None) -> BaseConverter:
    if name not in _converters:
        raise ValueError(f"Unknown converter: {name}")
    return _converters[name](config=config)


register_converter('cte', CTEConverter)
# Future converters would be registered here
# from .pivot import PivotConverter
# register_converter('pivot', PivotConverter)

################################################################################

File: C:\Users\User\python_code\sql_conversion_test\sql-query-converter\sql_converter\parsers\sql_parser.py
================================================================================
import re
import logging
from pathlib import Path
from typing import List, Dict, Optional, Generator, Tuple, Union, Match

from sql_converter.exceptions import SQLSyntaxError, ParserError


class SQLParser:
    """Parser for SQL statements with comprehensive error handling."""
    
    def __init__(self, dialect: str = 'ansi'):
        self.dialect = dialect.lower()
        self.logger = logging.getLogger(__name__)
        self.comment_handlers = {
            'ansi': self._handle_ansi_comments,
            'tsql': self._handle_tsql_comments,
            'mysql': self._handle_mysql_comments,
        }

    def validate_sql(self, sql: str) -> None:
        """
        Validates SQL syntax and raises specific SQLSyntaxError exceptions.
        
        Args:
            sql: The SQL statement to validate
            
        Raises:
            SQLSyntaxError: When SQL contains syntax errors
        """
        # Check for empty SQL
        if not sql or not sql.strip():
            raise SQLSyntaxError("Empty SQL statement", position=0, line=1)
        
        # Split into statements for statement-level validation
        try:
            statements = self.split_statements(sql, skip_validation=True)
        except Exception:
            # Fall back to whole script validation if splitting fails
            statements = [sql]
        
        # Validate each statement separately
        for stmt in statements:
            self._validate_statement(stmt)
    
    def _validate_statement(self, stmt: str) -> None:
        """
        Validates a single SQL statement.
        
        Args:
            stmt: The SQL statement to validate
            
        Raises:
            SQLSyntaxError: When SQL contains syntax errors
        """
        # Find line number for error messages
        def get_line_number(position: int) -> int:
            """Get line number for a position in the SQL string."""
            return stmt[:position].count('\n') + 1
        
        # Check for basic syntax errors with more precise error messages
        if "FROM WHERE" in stmt.upper():
            match = re.search(r'FROM\s+WHERE', stmt, re.IGNORECASE)
            if match:
                position = match.start()
                raise SQLSyntaxError(
                    "Missing table name between FROM and WHERE clauses",
                    position=position,
                    line=get_line_number(position)
                )
        
        # Check for unbalanced parentheses with position tracking
        if stmt.count('(') != stmt.count(')'):
            # Find the position where parentheses become unbalanced
            balance = 0
            for i, char in enumerate(stmt):
                if char == '(':
                    balance += 1
                elif char == ')':
                    balance -= 1
                    if balance < 0:
                        # Too many closing parentheses
                        raise SQLSyntaxError(
                            "Unbalanced parentheses: unexpected ')'",
                            position=i,
                            line=get_line_number(i)
                        )
            # If we get here with positive balance, there are too many opening parentheses
            if balance > 0:
                raise SQLSyntaxError(
                    f"Unbalanced parentheses: missing {balance} closing parentheses",
                    position=len(stmt),
                    line=get_line_number(len(stmt))
                )
        
        # Check for unbalanced quotes with detailed error messages
        try:
            self._check_balanced_quotes(stmt)
        except SQLSyntaxError as e:
            # Re-raise with line number information
            position = getattr(e, 'position', None)
            if position is not None:
                line = get_line_number(position)
                raise SQLSyntaxError(
                    e.message,
                    position=position,
                    line=line
                ) from None
            raise
        
        # Check for JOIN without ON clause
        join_without_on = re.search(r'\bJOIN\b(?:(?!\bON\b).)*?(?:\bWHERE\b|\bGROUP\s+BY\b|\bORDER\s+BY\b|$)', 
                                   stmt, re.IGNORECASE | re.DOTALL)
        if join_without_on and not re.search(r'\bCROSS\s+JOIN\b', stmt, re.IGNORECASE):
            # Exclude CROSS JOIN which doesn't need ON
            match_text = join_without_on.group(0)
            if not re.search(r'\bUSING\b', match_text, re.IGNORECASE):  # Also exclude JOIN USING
                position = join_without_on.start()
                raise SQLSyntaxError(
                    "JOIN clause missing ON condition",
                    position=position,
                    line=get_line_number(position)
                )
        
        # Check for invalid GROUP BY syntax - within a single statement
        group_where = re.search(r'\bGROUP\s+BY\b.*?\bWHERE\b', stmt, re.IGNORECASE | re.DOTALL)
        if group_where:
            position = group_where.start()
            raise SQLSyntaxError(
                "WHERE clause must come before GROUP BY",
                position=position,
                line=get_line_number(position)
            )

    def _check_balanced_quotes(self, sql: str) -> None:
        """
        Check for balanced single and double quotes in SQL.
        
        Args:
            sql: The SQL statement to check
            
        Raises:
            SQLSyntaxError: When quotes are unbalanced
        """
        # Track quotation state
        in_single_quote = False
        in_double_quote = False
        escaped = False
        
        for i, char in enumerate(sql):
            # Handle escape sequences
            if escaped:
                escaped = False
                continue
                
            if char == '\\':
                escaped = True
                continue
                
            # Toggle quote state
            if char == "'":
                # Handle escaped single quotes ('') in SQL
                if in_single_quote and i + 1 < len(sql) and sql[i + 1] == "'":
                    # This is an escaped quote, skip the next one
                    escaped = True
                    continue
                in_single_quote = not in_single_quote
                    
            elif char == '"':
                # Handle escaped double quotes ("") in SQL
                if in_double_quote and i + 1 < len(sql) and sql[i + 1] == '"':
                    # This is an escaped quote, skip the next one
                    escaped = True
                    continue
                in_double_quote = not in_double_quote
                
        # Check final state
        if in_single_quote:
            raise SQLSyntaxError("Unbalanced single quotes", position=len(sql) - 1)
        if in_double_quote:
            raise SQLSyntaxError("Unbalanced double quotes", position=len(sql) - 1)

    def split_statements(self, sql: str, skip_validation: bool = False) -> List[str]:
        """
        Split SQL into individual statements while handling comments, strings, and nesting.
        
        Args:
            sql: SQL code potentially containing multiple statements
            skip_validation: If True, skip initial SQL validation
            
        Returns:
            List of individual SQL statements
            
        Raises:
            ParserError: When the parser encounters an unrecoverable error
            SQLSyntaxError: When SQL contains syntax errors
        """
        # Validate the overall SQL first (unless skipped)
        if not skip_validation:
            try:
                self.validate_sql(sql)
            except SQLSyntaxError as e:
                self.logger.error(f"SQL validation error: {e}")
                raise
            
        statements = []
        current = []
        state = {
            'in_string': False,
            'string_char': None,
            'in_comment': False,
            'comment_type': None,
            'paren_depth': 0,
            'bracket_depth': 0,
            'escape_next': False,
        }

        # Use regex to replace comments with spaces
        # First, remove block comments (/* ... */)
        sql = re.sub(r'/\*.*?\*/', ' ', sql, flags=re.DOTALL)
        
        # Then handle line comments (--) by replacing until end of line
        # Make sure to preserve newlines
        sql = re.sub(r'--.*?(\n|$)', '\n', sql, flags=re.DOTALL)

        try:
            for i, char in enumerate(sql):
                # Handle string literals
                if state['in_string']:
                    if state['escape_next']:
                        state['escape_next'] = False
                    elif char == '\\':
                        state['escape_next'] = True
                    elif char == state['string_char']:
                        state['in_string'] = False
                        state['string_char'] = None
                elif char in ("'", '"'):
                    state['in_string'] = True
                    state['string_char'] = char
                
                # Handle parentheses and brackets (only when not in a string)
                if not state['in_string']:
                    if char == '(':
                        state['paren_depth'] += 1
                    elif char == ')':
                        state['paren_depth'] = max(0, state['paren_depth'] - 1)
                    
                    # Handle brackets for TSQL
                    if self.dialect == 'tsql':
                        if char == '[':
                            state['bracket_depth'] += 1
                        elif char == ']':
                            state['bracket_depth'] = max(0, state['bracket_depth'] - 1)
                
                # Add character to current statement
                current.append(char)
                
                # Check for statement termination
                if (char == ';' and 
                    not state['in_string'] and 
                    state['paren_depth'] == 0 and 
                    state['bracket_depth'] == 0):
                    
                    statement = ''.join(current).strip()
                    if statement:
                        statements.append(statement)
                    current = []
                    state.update({
                        'in_string': False,
                        'string_char': None,
                        'paren_depth': 0,
                        'bracket_depth': 0,
                        'escape_next': False,
                    })
                
        except Exception as e:
            # Convert any unexpected errors to ParserError with context
            position = i if 'i' in locals() else 0
            raise ParserError(
                f"Error while parsing SQL: {str(e)}",
                source=sql[:100] + '...' if len(sql) > 100 else sql
            ) from e

        # Add remaining content if not empty
        final_statement = ''.join(current).strip()
        if final_statement:
            statements.append(final_statement)

        # Filter out any empty statements
        return [stmt for stmt in statements if stmt]

    def _handle_ansi_comments(self, char: str, state: Dict, position: int) -> None:
        """
        Handle standard SQL comments (-- and /* */ style).
        
        Args:
            char: Current character being processed
            state: Current parser state dictionary
            position: Current position in the SQL string
        """
        # This method is deprecated as we now handle comments directly in split_statements
        pass

    def _handle_tsql_comments(self, char: str, state: Dict, position: int) -> None:
        """
        Handle T-SQL specific comments.
        
        Args:
            char: Current character being processed
            state: Current parser state dictionary
            position: Current position in the SQL string
        """
        # This method is deprecated as we now handle comments directly in split_statements
        pass

    def _handle_mysql_comments(self, char: str, state: Dict, position: int) -> None:
        """
        Handle MySQL specific comments (# style).
        
        Args:
            char: Current character being processed
            state: Current parser state dictionary
            position: Current position in the SQL string
        """
        # This method is deprecated as we now handle comments directly in split_statements
        pass

    def tokenize(self, sql: str) -> Generator[Tuple[str, str], None, None]:
        """
        Tokenize SQL into meaningful components.
        
        Args:
            sql: SQL statement to tokenize
            
        Returns:
            Generator yielding (token_type, token_value) tuples
            
        Raises:
            ParserError: When tokenization fails
        """
        try:
            # First, preprocess to remove comments
            clean_sql = self._remove_comments(sql)
            
            token_spec = [
                ('STRING',      r"'(''|[^'])*'"),     # Single-quoted strings
                ('STRING',      r'"([^"]|"")*"'),     # Double-quoted strings
                ('NUMBER',      r'\d+(\.\d+)?([eE][+-]?\d+)?'),  # Numbers
                ('KEYWORD',     r'\b(SELECT|INSERT|UPDATE|DELETE|FROM|WHERE|'
                                r'JOIN|INTO|CREATE|TEMP|TABLE|AS|AND|OR|'
                                r'GROUP BY|ORDER BY|HAVING|LIMIT)\b', re.IGNORECASE),
                ('IDENTIFIER',  r'[a-zA-Z_][a-zA-Z0-9_#@$]*'),  # Identifiers
                ('OPERATOR',    r'[+\-*/%=<>!~&|^]'),  # Operators
                ('PAREN',       r'[()]'),              # Parentheses
                ('BRACKET',     r'[\[\]]'),            # Brackets
                ('SEMICOLON',   r';'),                 # Statement terminator
                ('WHITESPACE',  r'\s+'),               # Whitespace
            ]

            tok_regex = '|'.join(
                f'(?P<{name}>{pattern})' for name, pattern in token_spec
            )
            flags = re.DOTALL | re.IGNORECASE
            
            for match in re.finditer(tok_regex, clean_sql, flags):
                kind = match.lastgroup
                value = match.group().strip()
                if kind == 'WHITESPACE':
                    continue
                yield (kind, value)
                
        except Exception as e:
            # Convert any unexpected errors to ParserError
            raise ParserError(
                f"Error during SQL tokenization: {str(e)}",
                source=sql[:100] + '...' if len(sql) > 100 else sql
            ) from e

    def _remove_comments(self, sql: str) -> str:
        """
        Remove SQL comments to simplify tokenization.
        
        Args:
            sql: SQL statement containing comments
            
        Returns:
            SQL with comments removed
        """
        try:
            # First, remove /* */ block comments
            pattern = r'/\*[\s\S]*?\*/'
            sql = re.sub(pattern, ' ', sql)
            
            # Then, remove -- line comments (up to end of line)
            pattern = r'--.*?$'
            sql = re.sub(pattern, ' ', sql, flags=re.MULTILINE)
            
            # Finally, remove # MySQL style comments
            pattern = r'#.*?$'
            sql = re.sub(pattern, ' ', sql, flags=re.MULTILINE)
            
            return sql
        except Exception as e:
            # Convert regex errors to ParserError
            raise ParserError(f"Error removing comments: {str(e)}")

    def parse_identifiers(self, sql: str) -> List[str]:
        """
        Extract all identifiers from SQL query.
        
        Args:
            sql: SQL statement to extract identifiers from
            
        Returns:
            List of SQL identifiers found
            
        Raises:
            ParserError: When identifier extraction fails
        """
        try:
            identifiers = []
            for kind, value in self.tokenize(sql):
                if kind == 'IDENTIFIER':
                    # Handle quoted identifiers
                    clean_value = value.strip('[]"\'`')
                    identifiers.append(clean_value)
            return identifiers
        except Exception as e:
            if isinstance(e, ParserError):
                raise
            # Convert other errors to ParserError
            raise ParserError(f"Error extracting identifiers: {str(e)}")

################################################################################

File: C:\Users\User\python_code\sql_conversion_test\sql-query-converter\sql_converter\parsers\__init__.py
================================================================================


################################################################################

File: C:\Users\User\python_code\sql_conversion_test\sql-query-converter\sql_converter\tests\conftest.py
================================================================================
import pytest
from pathlib import Path
import sys
import os
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '../..')))
from sql_converter.utils.config import ConfigManager

@pytest.fixture
def config_manager():
    manager = ConfigManager()
    manager.config = {
        'converters': ['cte'],
        'cte_converter': {
            'indent_spaces': 2,
            'temp_table_patterns': ['#.*']
        }
    }
    return manager

@pytest.fixture
def sample_sql_file(tmp_path):
    test_sql = """
    SELECT * INTO #temp FROM users;
    SELECT name FROM #temp;
    """
    file_path = tmp_path / "test.sql"
    file_path.write_text(test_sql)
    return file_path

################################################################################

File: C:\Users\User\python_code\sql_conversion_test\sql-query-converter\sql_converter\tests\fixtures\expected\create_temp_table.sql
================================================================================
WITH orders_summary AS (
  SELECT customer_id, SUM(total) AS total_spent
  FROM orders
  GROUP BY customer_id
)
SELECT * FROM orders_summary WHERE total_spent > 1000;

################################################################################

File: C:\Users\User\python_code\sql_conversion_test\sql-query-converter\sql_converter\tests\fixtures\expected\multiple_temps.sql
================================================================================
WITH temp1 AS (
  SELECT * FROM table1
),
temp2 AS (
  SELECT * FROM table2
)
SELECT t1.*, t2.* FROM temp1 t1 JOIN temp2 t2 ON t1.id = t2.id;

################################################################################

File: C:\Users\User\python_code\sql_conversion_test\sql-query-converter\sql_converter\tests\fixtures\expected\nested_temps.sql
================================================================================
WITH inner_temp AS (
  SELECT * FROM source_table
),
outer_temp AS (
  SELECT * FROM inner_temp
)
SELECT * FROM outer_temp;

################################################################################

File: C:\Users\User\python_code\sql_conversion_test\sql-query-converter\sql_converter\tests\fixtures\expected\pattern_matching.sql
================================================================================
WITH tmp_users AS (
  SELECT * FROM users
)
SELECT * FROM tmp_users;

################################################################################

File: C:\Users\User\python_code\sql_conversion_test\sql-query-converter\sql_converter\tests\fixtures\expected\permanent_table.sql
================================================================================
SELECT * INTO permanent_table FROM users;
SELECT * FROM permanent_table;

################################################################################

File: C:\Users\User\python_code\sql_conversion_test\sql-query-converter\sql_converter\tests\fixtures\expected\simple_select.sql
================================================================================
WITH users_temp AS (
  SELECT * FROM users
)
SELECT * FROM users_temp;

################################################################################

File: C:\Users\User\python_code\sql_conversion_test\sql-query-converter\sql_converter\tests\fixtures\expected\special_chars.sql
================================================================================
WITH temp_123 AS (
  SELECT * FROM [table-with-hyphen]
)
SELECT * FROM temp_123;

################################################################################

File: C:\Users\User\python_code\sql_conversion_test\sql-query-converter\sql_converter\tests\fixtures\expected\tsql_brackets.sql
================================================================================
WITH temp AS (
  SELECT [col1] FROM [dbo].[table]
)
SELECT [col1] FROM temp;

################################################################################

File: C:\Users\User\python_code\sql_conversion_test\sql-query-converter\sql_converter\tests\fixtures\expected\with_comments.sql
================================================================================
WITH commented_temp AS (
  SELECT * FROM users /* important table */
)
SELECT * FROM commented_temp;

################################################################################

File: C:\Users\User\python_code\sql_conversion_test\sql-query-converter\sql_converter\tests\fixtures\input\create_temp_table.sql
================================================================================
CREATE TEMP TABLE #orders_summary AS
SELECT customer_id, SUM(total) AS total_spent
FROM orders
GROUP BY customer_id;

SELECT * FROM #orders_summary WHERE total_spent > 1000;

################################################################################

File: C:\Users\User\python_code\sql_conversion_test\sql-query-converter\sql_converter\tests\fixtures\input\multiple_temps.sql
================================================================================
SELECT * INTO #temp1 FROM table1;
SELECT * INTO #temp2 FROM table2;
SELECT t1.*, t2.* FROM #temp1 t1 JOIN #temp2 t2 ON t1.id = t2.id;

################################################################################

File: C:\Users\User\python_code\sql_conversion_test\sql-query-converter\sql_converter\tests\fixtures\input\nested_temps.sql
================================================================================
SELECT * INTO #inner_temp FROM source_table;
SELECT * INTO #outer_temp FROM #inner_temp;
SELECT * FROM #outer_temp;

################################################################################

File: C:\Users\User\python_code\sql_conversion_test\sql-query-converter\sql_converter\tests\fixtures\input\pattern_matching.sql
================================================================================
SELECT * INTO #tmp_users FROM users;
SELECT * FROM #tmp_users;

################################################################################

File: C:\Users\User\python_code\sql_conversion_test\sql-query-converter\sql_converter\tests\fixtures\input\permanent_table.sql
================================================================================
SELECT * INTO permanent_table FROM users;
SELECT * FROM permanent_table;

################################################################################

File: C:\Users\User\python_code\sql_conversion_test\sql-query-converter\sql_converter\tests\fixtures\input\simple_select.sql
================================================================================
SELECT * INTO #users_temp FROM users;
SELECT * FROM #users_temp;

################################################################################

File: C:\Users\User\python_code\sql_conversion_test\sql-query-converter\sql_converter\tests\fixtures\input\special_chars.sql
================================================================================
SELECT * INTO #temp_123 FROM [table-with-hyphen];
SELECT * FROM #temp_123;

################################################################################

File: C:\Users\User\python_code\sql_conversion_test\sql-query-converter\sql_converter\tests\fixtures\input\tsql_brackets.sql
================================================================================
SELECT [col1] INTO #temp FROM [dbo].[table];
SELECT [col1] FROM #temp;

################################################################################

File: C:\Users\User\python_code\sql_conversion_test\sql-query-converter\sql_converter\tests\fixtures\input\with_comments.sql
================================================================================
-- Create temp table
SELECT * INTO #commented_temp FROM users /* important table */;
/*
Multi-line comment
SELECT * INTO #ignored_temp FROM logs;
*/
SELECT * FROM #commented_temp;

################################################################################

File: C:\Users\User\python_code\sql_conversion_test\sql-query-converter\sql_converter\tests\integration\test_cli.py
================================================================================
import pytest
from unittest.mock import patch
import argparse
import sys
from pathlib import Path
from sql_converter.cli import main, SQLConverterApp

def test_cli_help():
    # Skip using CliRunner and test more directly
    with patch('sys.argv', ['cli.py', '--help']):
        with patch('argparse.ArgumentParser.print_help') as mock_print_help:
            try:
                main()
            except SystemExit:
                pass
            mock_print_help.assert_called_once()

def test_cli_file_conversion(tmp_path, sample_sql_file):
    output_file = tmp_path / "output.sql"
    
    # Patch sys.argv directly
    with patch('sys.argv', [
        'cli.py',
        '-i', str(sample_sql_file),
        '-o', str(output_file),
        '-c', 'cte'
    ]):
        try:
            main()
        except SystemExit:
            pass  # Catch potential system exit
    
    # Verify the output
    assert output_file.exists()
    content = output_file.read_text()
    assert "WITH temp AS" in content
    assert "SELECT" in content

################################################################################

File: C:\Users\User\python_code\sql_conversion_test\sql-query-converter\sql_converter\tests\integration\test_integration.py
================================================================================
import pytest
import os
from pathlib import Path
from sql_converter.cli import SQLConverterApp
from sql_converter.converters.cte import CTEConverter

def test_full_conversion(tmp_path, config_manager):
    # Find the project root directory
    # Start from the current file and walk up until we find the sql_converter directory
    current_dir = Path(__file__).resolve().parent
    
    # Find the root directory that contains sql_converter
    root_dir = None
    search_dir = current_dir
    while search_dir != search_dir.parent:  # Stop at filesystem root
        if (search_dir / "sql_converter" / "tests" / "fixtures").exists():
            root_dir = search_dir
            break
        search_dir = search_dir.parent
    
    assert root_dir is not None, "Could not find project root directory"
    
    # Build paths based on the found root directory
    fixtures_dir = root_dir / "sql_converter" / "tests" / "fixtures" / "input"
    expected_dir = root_dir / "sql_converter" / "tests" / "fixtures" / "expected"
    
    print(f"Project root directory: {root_dir}")
    print(f"Looking for fixtures at: {fixtures_dir}")
    
    assert fixtures_dir.exists(), f"Fixtures directory not found at {fixtures_dir}"
    assert expected_dir.exists(), f"Expected directory not found at {expected_dir}"
    
    output_dir = tmp_path / "output"
    output_dir.mkdir(exist_ok=True)
    
    app = SQLConverterApp(
        converters={'cte': CTEConverter()},
        config=config_manager.config
    )
    app.process_directory(fixtures_dir, output_dir, ['cte'])
    
    # Verify all files were converted
    input_files = list(fixtures_dir.glob("**/*.sql"))
    output_files = list(output_dir.glob("**/*.sql"))
    assert len(output_files) > 0
    
    # Compare with expected results but normalize whitespace
    for input_file in input_files:
        relative = input_file.relative_to(fixtures_dir)
        output_file = output_dir / relative
        expected_file = expected_dir / relative
        
        if output_file.exists() and expected_file.exists():
            # Normalize whitespace for comparison
            import re
            output_text = re.sub(r'\s+', ' ', output_file.read_text().strip())
            expected_text = re.sub(r'\s+', ' ', expected_file.read_text().strip())
            # In test_integration.py, add debugging before assertion:
            print(f"Input file: {input_file}")
            print(f"File content: {input_file.read_text()}")
            print(f"Output: {output_text}")
            print(f"Expected: {expected_text}")
            assert output_text == expected_text

################################################################################

File: C:\Users\User\python_code\sql_conversion_test\sql-query-converter\sql_converter\tests\unit\converters\test_cte.py
================================================================================
import pytest
from sql_converter.converters.cte import CTEConverter

def test_basic_cte_conversion():
    sql = "SELECT * INTO #temp FROM users; SELECT * FROM #temp;"
    converter = CTEConverter()
    converted = converter.convert(sql)
    assert "WITH temp AS" in converted
    assert "SELECT * FROM temp" in converted

def test_multiple_temp_tables():
    sql = """
    CREATE TEMP TABLE #table1 AS SELECT * FROM a;
    SELECT * INTO #table2 FROM b;
    SELECT * FROM #table1 t1 JOIN #table2 t2 ON t1.id = t2.id;
    """
    converter = CTEConverter()
    converted = converter.convert(sql)
    assert "table1 AS" in converted
    assert "table2 AS" in converted
    assert "FROM table1" in converted
    assert "JOIN table2" in converted

def test_temp_table_pattern_matching():
    sql = "SELECT * INTO #my_temp FROM table;"
    converter = CTEConverter(config={'temp_table_patterns': ['#my_*']})
    converted = converter.convert(sql)
    assert "my_temp AS" in converted

def test_nested_temp_tables():
    sql = """
    SELECT * INTO #outer FROM (
        SELECT * FROM #inner
    );
    """
    converter = CTEConverter()
    converted = converter.convert(sql)
    assert "WITH outer AS" in converted
    assert "inner AS" in converted

################################################################################

File: C:\Users\User\python_code\sql_conversion_test\sql-query-converter\sql_converter\tests\unit\parsers\test_sql_parser.py
================================================================================
import pytest
from sql_converter.parsers.sql_parser import SQLParser

def test_statement_splitting():
    sql = """
    SELECT * FROM table; 
    -- Comment
    INSERT INTO #temp VALUES (1);
    """
    parser = SQLParser()
    statements = parser.split_statements(sql)
    assert len(statements) == 2
    assert "SELECT" in statements[0]
    assert "INSERT" in statements[1]

def test_tsql_bracket_handling():
    sql = "SELECT [col.name] FROM [dbo.table];"
    parser = SQLParser(dialect='tsql')
    statements = parser.split_statements(sql)
    assert len(statements) == 1
    assert "[col.name]" in statements[0]

def test_comment_handling():
    sql = """
    /* Multi-line 
       comment */
    SELECT 1; -- Line comment
    """
    parser = SQLParser()
    statements = parser.split_statements(sql)
    assert len(statements) == 1
    assert "SELECT" in statements[0]

################################################################################

File: C:\Users\User\python_code\sql_conversion_test\sql-query-converter\sql_converter\tests\unit\utils\test_config.py
================================================================================
import pytest
from unittest.mock import mock_open, patch
from sql_converter.utils.config import ConfigManager

def test_config_loading():
    yaml_content = """
    converters:
      - cte
      - pivot
    logging:
      level: DEBUG
    """
    # Ensure the mock correctly simulates a config file
    with patch("builtins.open", mock_open(read_data=yaml_content)):
        # Patch Path.exists and Path.is_file to return True for any path
        with patch("pathlib.Path.exists", return_value=True):
            with patch("pathlib.Path.is_file", return_value=True):
                manager = ConfigManager()
                # Force a specific path that will be mocked
                manager.config_paths = [manager.config_paths[0]]  # Just use the first path
                manager.load_config()
                
                # Verify the config was loaded correctly
                assert 'pivot' in manager.get('converters')
                assert manager.get('logging.level') == 'DEBUG'

def test_config_priority():
    manager = ConfigManager()
    manager.config = {'converters': ['base']}
    manager.update_from_cli({'convert': ['cte']})
    assert manager.config['converters'] == ['cte']

################################################################################

File: C:\Users\User\python_code\sql_conversion_test\sql-query-converter\sql_converter\utils\config.py
================================================================================
import os
import logging
from pathlib import Path
from typing import Dict, Any, Optional, List, Union
import yaml
from dotenv import load_dotenv

from sql_converter.exceptions import ConfigError


class ConfigManager:
    """
    Manages configuration from multiple sources with precedence rules.
    """
    
    def __init__(self):
        """Initialize the configuration manager."""
        self.config: Dict[str, Any] = {}
        self.logger = logging.getLogger(__name__)
        
        # Try to load environment variables
        try:
            load_dotenv()  # Load environment variables
        except Exception as e:
            self.logger.warning(f"Failed to load environment variables: {str(e)}")
        
        # Default search paths for config files
        self.config_paths = [
            Path("sql_converter/config/default.yml"),
            Path(os.getenv("SQL_CONVERTER_CONFIG", "")),
            Path("~/.config/sql_converter/config.yml").expanduser(),
            Path("./sql_converter.yml"),
        ]

    def load_config(self) -> None:
        """
        Load configuration from first found valid config file.
        
        Raises:
            ConfigError: When config loading fails critically
        """
        loaded = False
        errors = []
        
        # Try each path in order
        for path in self.config_paths:
            if not path or not path.exists() or not path.is_file():
                continue
                
            try:
                with open(path, 'r') as f:
                    loaded_config = yaml.safe_load(f)
                    
                # Validate config structure
                if not isinstance(loaded_config, dict):
                    self.logger.warning(f"Invalid config format in {path}: not a dictionary")
                    errors.append(f"Config at {path} is not a dictionary")
                    continue
                
                self.config = loaded_config
                self.logger.info(f"Loaded config from {path}")
                loaded = True
                break
                
            except Exception as e:
                error_msg = f"Failed to load config from {path}: {str(e)}"
                self.logger.warning(error_msg)
                errors.append(error_msg)
        
        # If no config loaded, use defaults but raise warning
        if not loaded:
            self.logger.warning("No valid config file found, using defaults")
            self.config = {
                'converters': ['cte'],
                'logging': {'level': 'INFO', 'file': 'conversions.log'}
            }
            
            # If there were critical errors in configuration loading, raise exception
            if any("Permission denied" in err for err in errors):
                raise ConfigError(
                    "Cannot access configuration files due to permission issues",
                    "\n".join(errors)
                )

    def get(self, key: str, default: Optional[Any] = None) -> Any:
        """
        Get config value using dot notation (e.g. 'logging.level').
        
        Args:
            key: Config key using dot notation
            default: Default value if key not found
            
        Returns:
            Config value or default
            
        Raises:
            ConfigError: When key is invalid
        """
        if not key:
            raise ConfigError("Empty configuration key provided")
            
        keys = key.split('.')
        value = self.config
        
        try:
            for k in keys:
                if not isinstance(value, dict):
                    self.logger.debug(f"Config path '{key}' traversal failed at '{k}': not a dictionary")
                    return default
                value = value.get(k)
                if value is None:
                    return default
            return value
        except Exception as e:
            self.logger.debug(f"Error retrieving config value for '{key}': {str(e)}")
            return default

    def update_from_cli(self, cli_args: Dict[str, Any]) -> None:
        """
        Merge CLI arguments into config.
        
        Args:
            cli_args: CLI arguments dictionary
            
        Raises:
            ConfigError: When CLI arguments are invalid
        """
        if not isinstance(cli_args, dict):
            raise ConfigError(f"CLI arguments must be a dictionary, got {type(cli_args).__name__}")
            
        try:
            # Apply CLI arguments with proper validation
            if 'convert' in cli_args:
                converters = cli_args['convert']
                if not isinstance(converters, list):
                    raise ConfigError(f"'convert' must be a list, got {type(converters).__name__}")
                self.config['converters'] = converters
                
            if 'input' in cli_args:
                input_path = cli_args['input']
                if not isinstance(input_path, (str, Path)):
                    raise ConfigError(f"'input' must be a string or Path, got {type(input_path).__name__}")
                self.config['input_path'] = input_path
                
            if 'output' in cli_args:
                output_path = cli_args['output']
                if not isinstance(output_path, (str, Path)):
                    raise ConfigError(f"'output' must be a string or Path, got {type(output_path).__name__}")
                self.config['output_path'] = output_path
                
        except Exception as e:
            if isinstance(e, ConfigError):
                raise
            raise ConfigError(f"Error updating configuration from CLI: {str(e)}")
            
    def validate_config(self) -> List[str]:
        """
        Validate the loaded configuration.
        
        Returns:
            List of validation errors (empty if valid)
            
        Raises:
            ConfigError: When validation fails critically
        """
        errors = []
        
        # Check for required sections
        if 'converters' not in self.config:
            errors.append("Missing 'converters' section in configuration")
            
        # Validate converters
        converters = self.config.get('converters', [])
        if not isinstance(converters, list):
            errors.append(f"'converters' must be a list, got {type(converters).__name__}")
        elif not converters:
            errors.append("No converters specified in configuration")
            
        # Validate converter-specific configs
        for converter in converters:
            converter_config_key = f"{converter}_converter"
            converter_config = self.config.get(converter_config_key)
            
            if converter_config is not None and not isinstance(converter_config, dict):
                errors.append(f"'{converter_config_key}' must be a dictionary")
                
        # Validate logging config
        logging_config = self.config.get('logging', {})
        if not isinstance(logging_config, dict):
            errors.append(f"'logging' must be a dictionary, got {type(logging_config).__name__}")
        else:
            # Check log level
            log_level = logging_config.get('level')
            if log_level and log_level not in ('DEBUG', 'INFO', 'WARNING', 'ERROR', 'CRITICAL'):
                errors.append(f"Invalid log level: '{log_level}'")
                
            # Check log file
            log_file = logging_config.get('file')
            if log_file and not isinstance(log_file, (str, Path)):
                errors.append(f"'logging.file' must be a string or Path, got {type(log_file).__name__}")
                
        # Return all validation errors
        return errors
            
    def merge_configs(self, other_config: Dict[str, Any]) -> None:
        """
        Merge another config dictionary into this one.
        
        Args:
            other_config: Config dictionary to merge
            
        Raises:
            ConfigError: When merging fails
        """
        if not isinstance(other_config, dict):
            raise ConfigError(f"Cannot merge non-dictionary config: {type(other_config).__name__}")
            
        try:
            self._recursive_merge(self.config, other_config)
        except Exception as e:
            raise ConfigError(f"Error merging configurations: {str(e)}")
            
    def _recursive_merge(self, base: Dict[str, Any], overlay: Dict[str, Any]) -> None:
        """
        Recursively merge overlay dictionary into base dictionary.
        
        Args:
            base: Base dictionary to merge into
            overlay: Overlay dictionary with values to merge
        """
        for key, value in overlay.items():
            if key in base and isinstance(base[key], dict) and isinstance(value, dict):
                # Recursively merge nested dictionaries
                self._recursive_merge(base[key], value)
            else:
                # Otherwise replace or add the value
                base[key] = value

################################################################################

File: C:\Users\User\python_code\sql_conversion_test\sql-query-converter\sql_converter\utils\logging.py
================================================================================
# sql_converter/utils/logging.py
import logging
from typing import Optional

def setup_logging(level: str = 'INFO', log_file: Optional[str] = None) -> None:
    """Configure logging system"""
    level = getattr(logging, level.upper(), logging.INFO)
    
    handlers = [
        logging.StreamHandler()
    ]
    
    if log_file:
        handlers.append(logging.FileHandler(log_file))
    
    logging.basicConfig(
        level=level,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=handlers
    )

################################################################################

File: C:\Users\User\python_code\sql_conversion_test\sql-query-converter\sql_converter\utils\__init__.py
================================================================================


################################################################################

